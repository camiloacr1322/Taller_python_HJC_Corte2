# -*- coding: utf-8 -*-
"""Copia de prueba python

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13yAvk-VFNFdbhWbSnVN7AvwvdcQZKqL-
"""

!pip install scikit-posthocs

!pip install prince



import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from scipy.stats import shapiro
from scipy.stats import levene
from scipy.stats import f_oneway
import seaborn as sns
from scipy.stats import kruskal
import scikit_posthocs as sp
import scipy.stats as stats
import seaborn as sns
from scipy.stats import chi2_contingency
import prince
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score


df = pd.read_excel('/content/base_datos_completa_NNA_TI_anon.xlsx', sheet_name='BD')



# Lista de columnas que quieres conservar
cols_demograficas = [
    "Id_fic","NACIONALIDAD", "SEXO", "ESTADO CIVIL",
    "EDAD", "CURSO DE VIDA", "ETNIA",
    "POBLACIÃ“N DIFERENCIAL Y DE INCLUSIÃ“N", "OCUPACIÃ“N",
    "IdNivelEducativo","VÃNCULO CON EL JEFE DE HOGAR",
    "Localidad_fic","ESTRATO SOCIOECONÃ“MICO"
]

# Crear un nuevo DataFrame solo con esas variables
af = df[cols_demograficas].copy()

"""Se trabajan con solo estas variables"""

af = af.replace(99999, pd.NA)

"""Codigo de duplicados"""

# Verificar si hay IDs duplicados
duplicados = df['Id_fic'].duplicated()
hay_duplicados = duplicados.any()

print("Hay IDs duplicados:", hay_duplicados)

# Ver cuÃ¡les IDs estÃ¡n duplicados
print("IDs duplicados:")
print(df.loc[duplicados, 'Id_fic'])

num_unicos = df['Id_fic'].nunique()
num_total = len(df)

print(f"IDs Ãºnicos: {num_unicos}, Total filas: {num_total}")
print("Todos los IDs son Ãºnicos?", num_unicos == num_total)
print("Numero de ID duplicados", num_total-num_unicos)

af_sin_duplicados = af.drop_duplicates(subset='Id_fic', keep='first')
af_sin_duplicados.shape

"""Codigo de faltantes"""

faltantes = af_sin_duplicados.isna().sum().sort_values(ascending=False)

# Mostrar siempre todas las columnas
print("Valores faltantes por variable:\n")
print(faltantes)

# --- GrÃ¡fico ---
plt.figure(figsize=(12, 6))
faltantes.plot(kind='bar', color='skyblue', edgecolor='black')

plt.title("Valores faltantes por variable", fontsize=14, weight='bold')
plt.xlabel("Variable")
plt.ylabel("NÃºmero de valores faltantes")
plt.xticks(rotation=90)
plt.grid(axis='y', linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

# Elimina filas con al menos un valor faltante
af_completa = af_sin_duplicados.dropna()

# Mostrar cuÃ¡ntas filas quedaron
print(f"Filas originales: {af_sin_duplicados.shape[0]}")
print(f"Filas despuÃ©s de eliminar faltantes: {af_completa.shape[0]}")

# Opcional: verificaciÃ³n rÃ¡pida de que ya no hay NA
print("\nÂ¿AÃºn hay valores faltantes?")
print(af_completa.isna().sum().sum() == 0)

af_completa.to_excel("af_completa.xlsx", index=False)

# Mantener solo las filas donde 'ESTRATO SOCIOECONÃ“MICO' no tiene valores faltantes
af_filtrado = af_sin_duplicados.dropna(subset=["ESTRATO SOCIOECONÃ“MICO"])

# Mostrar informaciÃ³n del resultado
print(f"Filas originales: {af_sin_duplicados.shape[0]}")
print(f"Filas despuÃ©s de eliminar faltantes en 'ESTRATO SOCIOECONÃ“MICO': {af_filtrado.shape[0]}")

# Comprobar si aÃºn hay nulos en esa variable
print("\nValores faltantes restantes en 'ESTRATO SOCIOECONÃ“MICO':")
print(af_filtrado['ESTRATO SOCIOECONÃ“MICO'].isna().sum())

af_filtrado.to_excel("af_filtrado.xlsx", index=False)

tabla_univar = af_filtrado["ESTRATO SOCIOECONÃ“MICO"].value_counts().reset_index()
tabla_univar.columns = ["ESTRATO SOCIOECONÃ“MICO", "Frecuencia"]
print(tabla_univar)

plt.figure(figsize=(10, 6))
plt.bar(tabla_univar["ESTRATO SOCIOECONÃ“MICO"], tabla_univar["Frecuencia"], color='skyblue')

# AÃ±adir etiquetas de frecuencia
for i, frecuencia in enumerate(tabla_univar["Frecuencia"]):
    plt.text(i, frecuencia + 100, str(frecuencia), ha='center', va='bottom')


plt.title("DistribuciÃ³n por Estrato SocioeconÃ³mico")
plt.xlabel("Estrato SocioeconÃ³mico")
plt.ylabel("Frecuencia")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Con totales
pd.crosstab(af_filtrado["CURSO DE VIDA"], af_filtrado["ESTRATO SOCIOECONÃ“MICO"], margins=True, dropna=False)

# Porcentajes por columna
#pd.crosstab(af["SEXO"], af["ESTRATO SOCIOECONÃ“MICO"], normalize="columns") * 100

# Porcentajes por fila
#pd.crosstab(af["SEXO"], af["ESTRATO SOCIOECONÃ“MICO"], normalize="index") * 100

# Crear una tabla de contingencia para la frecuencia de CURSO DE VIDA y ESTRATO SOCIOECONÃ“MICO
crosstab_curso_estrato = pd.crosstab(af["CURSO DE VIDA"], af["ESTRATO SOCIOECONÃ“MICO"])

# Crear el mapa de calor
plt.figure(figsize=(12, 8))
sns.heatmap(crosstab_curso_estrato, annot=True, fmt='d', cmap='YlGnBu', linewidths=.5)

plt.title("DistribuciÃ³n de Curso de Vida por Estrato SocioeconÃ³mico (Mapa de Calor)")
plt.xlabel("Estrato SocioeconÃ³mico")
plt.ylabel("Curso de Vida")
plt.tight_layout()
plt.show()

# Create a cross-tabulation for educational level by socioeconomic stratum, including combinations with no data
crosstab_nivel_estrato = pd.crosstab(af["IdNivelEducativo"], af["ESTRATO SOCIOECONÃ“MICO"], dropna=False)

# Create the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(crosstab_nivel_estrato, annot=True, fmt='d', cmap='YlGnBu', linewidths=.5)

plt.title("DistribuciÃ³n del Nivel Educativo por Estrato SocioeconÃ³mico (Mapa de Calor)")
plt.xlabel("Estrato SocioeconÃ³mico")
plt.ylabel("Nivel Educativo")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Asegurar tipo numÃ©rico de edad
af_filtrado["EDAD"] = pd.to_numeric(af_filtrado["EDAD"], errors="coerce")

# Agrupar por estrato socioeconÃ³mico y calcular media y tamaÃ±o de muestra
tabla_media = (
    af_filtrado.groupby("ESTRATO SOCIOECONÃ“MICO", dropna=False)["EDAD"]
    .agg(Media_Edad="mean", N="count")
    .reset_index()
)

# Mostrar tabla resultante
print("ðŸ“Š Media de edad y nÃºmero de casos por estrato socioeconÃ³mico:\n")
display(tabla_media)

# Crear la grÃ¡fica de barras
plt.figure(figsize=(12, 8)) # Aumentar tamaÃ±o de la figura
bars = plt.bar(tabla_media["ESTRATO SOCIOECONÃ“MICO"], tabla_media["Media_Edad"], color='skyblue', edgecolor='black') # Cambiar color y aÃ±adir borde

# AÃ±adir etiquetas de frecuencia (N) y media de edad en las barras
for bar, n, mean_edad in zip(bars, tabla_media["N"], tabla_media["Media_Edad"]):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,
             f'N={n}\nMedia={mean_edad:.2f}',
             ha='center', va='bottom', fontsize=9)

# AÃ±adir un poco de espacio extra en la parte superior del grÃ¡fico para las etiquetas
plt.ylim(0, tabla_media["Media_Edad"].max() * 1.2)


# AÃ±adir etiquetas
plt.title("Media de Edad por Estrato SocioeconÃ³mico con Frecuencia y Media", fontsize=16, weight='bold') # Aumentar tamaÃ±o y poner negrita
plt.xlabel("Estrato SocioeconÃ³mico", fontsize=12) # Aumentar tamaÃ±o
plt.ylabel("Media de Edad", fontsize=12) # Aumentar tamaÃ±o
plt.xticks(rotation=45, ha='right', fontsize=10) # Aumentar tamaÃ±o y ajustar rotaciÃ³n
plt.yticks(fontsize=10) # Aumentar tamaÃ±o
plt.grid(axis='y', linestyle='--', alpha=0.7) # AÃ±adir cuadrÃ­cula
plt.tight_layout()
plt.show()

# Asegurar tipo numÃ©rico de edad y eliminar filas con NaN en ESTRATO SOCIOECONÃ“MICO
af_filtered_for_density = af.dropna(subset=["EDAD", "ESTRATO SOCIOECONÃ“MICO"]).copy()
af_filtered_for_density["EDAD"] = pd.to_numeric(af_filtered_for_density["EDAD"], errors="coerce")


# Create a FacetGrid for density plots of Age by Socioeconomic Stratum
g = sns.FacetGrid(af_filtered_for_density, col="ESTRATO SOCIOECONÃ“MICO", col_wrap=3, height=4, sharey=False)
g.map(sns.kdeplot, "EDAD", fill=True)

g.fig.suptitle("DistribuciÃ³n de Densidad de Edad por Estrato SocioeconÃ³mico (GrÃ¡ficos Separados)", y=1.02)
g.set_titles("Estrato: {col_name}")
g.set_axis_labels("Edad", "Densidad")
plt.tight_layout()
plt.show()

for estrato, grupo in af_filtrado.groupby("ESTRATO SOCIOECONÃ“MICO"):
    stat, p = shapiro(grupo["EDAD"].dropna())
    print(f"Estrato {estrato}: p-valor = {p:.4f}")

"""Shapiro no funciona por el N de los grupos"""

grupos = [g["EDAD"].dropna() for _, g in af_filtrado.groupby("ESTRATO SOCIOECONÃ“MICO")]
stat, p = levene(*grupos)
print(f"Prueba de Levene: p-valor = {p:.4f}")

"""Leven no se afecta por nada y no se recahza hipotesis nula, las varinzas son homecdasticas, supuesto cumplido"""

grupos = [g["EDAD"].dropna() for _, g in af_filtrado.groupby("ESTRATO SOCIOECONÃ“MICO")]
stat, p = f_oneway(*grupos)
print(f"ANOVA: F = {stat:.3f}, p-valor = {p:.4f}")

"""La pruea Anova nos da diferencias en los grupo, pero no es significativo"""

plt.figure(figsize=(8, 5))
sns.boxplot(x="ESTRATO SOCIOECONÃ“MICO", y="EDAD", data=af_filtrado)
plt.title("Boxplot de la Edad por Estrato SocioeconÃ³mico")
plt.show()

# Filtrar solo estratos con al menos 3 observaciones
conteo = af_filtrado.groupby("ESTRATO SOCIOECONÃ“MICO")["EDAD"].count()
estratos_validos = conteo[conteo >= 3].index
af_validos = af_filtrado[af_filtrado["ESTRATO SOCIOECONÃ“MICO"].isin(estratos_validos)]

# Ejecutar prueba de Kruskal
grupos = [g["EDAD"].dropna() for _, g in af_validos.groupby("ESTRATO SOCIOECONÃ“MICO")]
stat, p = kruskal(*grupos)

print(f"ðŸ“Š Prueba de Kruskal-Wallis: H = {stat:.3f}, p-valor = {p:.4f}")

if p < 0.05:
    print("âž¡ï¸ Hay diferencias significativas en la edad entre los estratos.")
else:
    print("âž¡ï¸ No se detectan diferencias significativas entre los estratos.")

# --- 1ï¸âƒ£ Filtrar el estrato 6 ---
af_sin6 = af_filtrado[af_filtrado["ESTRATO SOCIOECONÃ“MICO"] != "6. Alto"]

# --- 2ï¸âƒ£ Prueba de Kruskalâ€“Wallis ---
grupos = [grupo["EDAD"].dropna() for _, grupo in af_sin6.groupby("ESTRATO SOCIOECONÃ“MICO")]
kw_stat, kw_p = stats.kruskal(*grupos)

print(f"ðŸ“Š Resultado de Kruskalâ€“Wallis (sin estrato 6): estadÃ­stico={kw_stat:.4f}, p-valor={kw_p:.4f}")

# --- 3ï¸âƒ£ Prueba post hoc de Dunn ---
posthoc = sp.posthoc_dunn(
    af_sin6,
    val_col="EDAD",
    group_col="ESTRATO SOCIOECONÃ“MICO",
    p_adjust="bonferroni"
)

print("\nðŸ”Ž Comparaciones mÃºltiples (Dunn con correcciÃ³n Bonferroni):")
display(posthoc)

"""Se observa que las medias de la edad de los estratos son entre 3 y 1"""

# Tabla de conteo entre Localidad y Estrato
tabla_conteo = pd.crosstab(
    af_filtrado["Localidad_fic"],
    af_filtrado["ESTRATO SOCIOECONÃ“MICO"],
    dropna=False
)

print("ðŸ“Š Conteo de registros por Localidad y Estrato:\n")
display(tabla_conteo)

# Tabla de proporciones por fila (dentro de cada localidad)
tabla_prop = pd.crosstab(
    af_filtrado["Localidad_fic"],
    af_filtrado["ESTRATO SOCIOECONÃ“MICO"],
    normalize="index"
) * 100

print("ðŸ“ˆ Porcentaje por estrato dentro de cada localidad:\n")
display(tabla_prop.round(2))

chi2, p, dof, expected = chi2_contingency(tabla_conteo)

print(f"ðŸ“Š Chi-cuadrado = {chi2:.4f}, gl = {dof}, p-valor = {p:.4f}")
if p < 0.05:
    print("âœ… Existe asociaciÃ³n significativa entre localidad y estrato.")
else:
    print("âŒ No se encontrÃ³ asociaciÃ³n significativa entre localidad y estrato.")

"""Analisis de correspondencia"""

tabla = pd.crosstab(af_filtrado["Localidad_fic"], af_filtrado["ESTRATO SOCIOECONÃ“MICO"], dropna=False)
print("Tabla de contingencia (muestra):")
display(tabla.head())
# Crear modelo de correspondencias simples
ca = prince.CA(n_components=5, n_iter=10, copy=True, check_input=True, engine='sklearn', random_state=42)
ca = ca.fit(tabla)

# coordenadas principales (filas y columnas)
rows_coords = ca.row_coordinates(tabla)      # filas: localidades
cols_coords = ca.column_coordinates(tabla)   # columnas: estratos

# autovalores (inercia por dimensiÃ³n) y % explicado
# prince expone 'eigenvalues_' y 'explained_inertia_' en versiones recientes; si no, se usan eigenvalues_
try:
    eigen = np.array(ca.eigenvalues_)
except Exception:
    eigen = np.array(ca.eigenvalues_)
explained = eigen / eigen.sum()
cum_explained = explained.cumsum()

print("\nAutovalores (inercia) por dimensiÃ³n:", np.round(eigen, 6))
print("Porcentaje de varianza explicada por dimensiÃ³n (%):", np.round(explained * 100, 3))
print("Varianza explicada acumulada (%):", np.round(cum_explained * 100, 3))

# 3.4 CÃ¡lculo prÃ¡ctico de cosÂ² (por fila y por columna) sobre las 2 dimensiones
# cos2_ik = (coord_ik^2) / (sum over dims coord_ij^2)
rows_sq = (rows_coords**2)
rows_dist2 = rows_sq.sum(axis=1)
rows_cos2 = rows_sq.divide(rows_dist2, axis=0).fillna(0)   # proporciÃ³n de la inercia por dimensiÃ³n

cols_sq = (cols_coords**2)
cols_dist2 = cols_sq.sum(axis=1)
cols_cos2 = cols_sq.divide(cols_dist2, axis=0).fillna(0)

# 3.5 Contribuciones aproximadas por dimensiÃ³n
# FÃ³rmula prÃ¡ctica: cont_ik = (coord_ik^2) / eigen_k, luego normalizar a % por dimensiÃ³n.
cont_rows = pd.DataFrame(index=rows_coords.index)
cont_cols = pd.DataFrame(index=cols_coords.index)
for k in range(rows_coords.shape[1]):
    cont_rows[f"Dim{k+1}"] = (rows_coords.iloc[:, k]**2) / eigen[k]
    cont_cols[f"Dim{k+1}"] = (cols_coords.iloc[:, k]**2) / eigen[k]

# Normalizar para que sumen 1 (por dimensiÃ³n)
cont_rows_pct = cont_rows.divide(cont_rows.sum(axis=0), axis=1) * 100
cont_cols_pct = cont_cols.divide(cont_cols.sum(axis=0), axis=1) * 100

# Mostrar tablas resumidas
print("\n--- Top contribuciones filas (Localidades) por Dim1 ---")
display(cont_rows_pct["Dim1"].sort_values(ascending=False).head(10))

print("\n--- Top contribuciones columnas (Estratos) por Dim1 ---")
display(cont_cols_pct["Dim1"].sort_values(ascending=False).head(10))

# Coordenadas de filas y columnas
row_coords = ca.row_coordinates(tabla)
col_coords = ca.column_coordinates(tabla)

plt.figure(figsize=(8,6))

# Graficar filas (categorÃ­as de CURSO DE VIDA)
plt.scatter(row_coords[0], row_coords[1], label='Filas (Localidades)')
for i, txt in enumerate(row_coords.index):
    plt.text(row_coords.iloc[i,0], row_coords.iloc[i,1], txt)

# Graficar columnas (categorÃ­as de ESTRATO SOCIOECONÃ“MICO)
plt.scatter(col_coords[0], col_coords[1], marker='s', label='Columnas (Estrato)', alpha=0.7)
for i, txt in enumerate(col_coords.index):
    plt.text(col_coords.iloc[i,0], col_coords.iloc[i,1], txt)

plt.axhline(0, color='black', linewidth=0.5)
plt.axvline(0, color='black', linewidth=0.5)

plt.title("Correspondencias Simples - Dimensiones 1 y 2")
plt.xlabel("DimensiÃ³n 1")
plt.ylabel("DimensiÃ³n 2")
plt.legend()
plt.show()

# Cluster

#ruta_xlsx = "RUTA DE LA BASE DE DATOS"
#df = pd.read_excel(ruta_xlsx)
vars_cat = ["SEXO", "CURSO DE VIDA", "ETNIA", "OCUPACIÃ“N", "Localidad_fic"]
X_cat = df[vars_cat].copy()
X_cat = X_cat.dropna().reset_index(drop=True)
print("Dimensiones X_cat:", X_cat.shape)
print(X_cat.head())

## One-Hot encoding para usar un mÃ©todo de clÃºster estÃ¡ndar

X_enc = pd.get_dummies(X_cat, drop_first=False)
print("Dimensiones codificadas:", X_enc.shape)

ks = range(2, 9)
inertias = []
sil_scores = []

for k in ks:
    km = KMeans(n_clusters=k, n_init=20, random_state=42)
    labels = km.fit_predict(X_enc)
    inertias.append(km.inertia_)
    sil_scores.append(silhouette_score(X_enc, labels))

plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(ks, inertias, marker='o')
plt.title("Curva del codo (Inertia)")
plt.xlabel("k"); plt.ylabel("Inertia")

plt.subplot(1,2,2)
plt.plot(ks, sil_scores, marker='o')
plt.title("Silhouette vs k")
plt.xlabel("k"); plt.ylabel("Silhouette")
plt.tight_layout()
plt.show()

print("Inertias:", dict(zip(ks, inertias)))
print("Silhouette:", dict(zip(ks, sil_scores)))

k_final = 6  
km = KMeans(n_clusters=k_final, n_init=20, random_state=42)
cluster = km.fit_predict(X_enc)
df_clusters = X_cat.copy()
df_clusters["cluster"] = cluster

vars_perfil = ["SEXO", "CURSO DE VIDA", "OCUPACIÃ“N", "Localidad_fic"]  # agrega "PROGRAMA" si la tienes


#FunciÃ³n: tabla % por clÃºster de una variable categÃ³rica

def tabla_porcentual(dfc, var):
    # % por clÃºster (filas = clusters)
    ct = pd.crosstab(dfc["cluster"], dfc[var], normalize="index") * 100
    return ct.round(1)

# Mostrar top-k categorÃ­as por clÃºster para cada variable
def topk_por_cluster(dfc, var, k=5):
    ct = pd.crosstab(dfc["cluster"], dfc[var], normalize="index") * 100
    top = {}
    for cl in sorted(dfc["cluster"].unique()):
        fila = ct.loc[cl].sort_values(ascending=False).head(k)
        top[cl] = fila
    return top  

for v in vars_perfil:
    print(f"\n== {v} (% por clÃºster) ==")
    print(tabla_porcentual(df_clusters, v))
    top = topk_por_cluster(df_clusters, v, k=5)
    print(f"\nTop-5 categorÃ­as de {v} por clÃºster:")
    for cl, serie in top.items():
        print(f"  cluster {cl}:\n{serie.to_string()}\n")

# Heatmap por variable (porcentaje dentro de clÃºster)
for v in vars_perfil:
    plt.figure(figsize=(12, 4 + 0.2*len(df_clusters[v].unique())))
    ct = tabla_porcentual(df_clusters, v)
    sns.heatmap(ct, annot=True, fmt=".1f", cmap="Blues")
    plt.title(f"{v} - % por clÃºster")
    plt.xlabel(v)
    plt.ylabel("cluster")
    plt.tight_layout()
    plt.show()

# Barras apiladas por variable (porcentaje dentro de clÃºster)
for v in vars_perfil:
    ct = pd.crosstab(df_clusters["cluster"], df_clusters[v], normalize="index") * 100
    ax = ct.plot(kind="bar", stacked=True, figsize=(12,5))
    plt.ylabel("% dentro de clÃºster")
    plt.title(f"DistribuciÃ³n de {v} por clÃºster")
    plt.legend(bbox_to_anchor=(1.02, 1), loc="upper left", ncol=1)
    plt.tight_layout()
    plt.show()

# Correspondencia clÃºster Ã— estrato 
if "ESTRATO SOCIOECONÃ“MICO" in df.columns:
    tmp = df.loc[df_clusters.index] 
    cruz = pd.crosstab(tmp["ESTRATO SOCIOECONÃ“MICO"], df_clusters["cluster"], normalize="index") * 100
    print("\n== ESTRATO SOCIOECONÃ“MICO (% filas por estrato, columnas = clÃºster) ==")
    print(cruz.round(1))
